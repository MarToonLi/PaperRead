对比学习

## 《A Simple Framework for Contrastive Learning of Visual Representations》

​		创新点在于组合：抛却对其性能的对比分析部分，在数据增强方面，数据增强方式及组合方式对模型的影响程度的分析方面；目标函数的探讨方面；基础结构的深度和宽度以及训练时长以训练batch_size的大小的对比实验方面。



### 摘要

提出了一个不需要特殊结构或者内存库的对比自监督学习算法。对其学习到有用表示信息的方式是，系统地分析SimCLR框架的主要组成部分。

- 数据增强方式在定义有效决策任务中，扮演了很重要的角色；
- 表征和对比损失之间的一个可学习的非线性转换，持续提升学到的表征的质量；
- 较大的batch_size和更多的参数迭代次数有利于对比学习的表征学习（相比于监督学习）；

### 引言

 无监督的学习到有效的视觉表征是一个长期存在的问题。主流的方法分为两类：生成式和判别式。

- 生成式方法在输入空间中生成模型的像素或者通过其他方式对像素进行建模。但是像素级别的生成方法是计算昂贵的，同时对于表征学习而言可能并不必要。
- 判别时方法借助与监督学习中使用的那些目标函数以学习表征，但是训练网络执行pretext任务，其中pretext任务中的标签和输入来源于为被标记的数据集。

许多方法通过启发式来设计pretext任务，但是这种设计方式限制了以学习到的表示的泛化性。

**而基于潜在空间中的对比学习的判别式方法已经显现出很大的潜力**。**而这里我们要引入的SimCLR框架要更加简单，同时效能达到当前前沿技术水平。**—— **简单**在于：既不需要特殊的架构，也不需要内存块。

本文的突出贡献点：

- 多中数据增强操作有利于产生有效的表征，同时无监督学习在该模型下的受益程度要远远高于监督学习。
- 学习到的表征和对比损失函数之间的 **一个可学习性的非线性转换** 提升了学习到的表征的质量；
- 通过对比交叉熵损失函数进行表征学习得益于归一化签入和适当调整的温度参数temperature parameter。
- 相比于监督学习，对比学习得益于更大的批量和更长的训练时间；同时，与监督学习一样，对比学习得益于更深和更宽的网络模型。

### 方法

#### 1 对比学习框架

SimCLR框架借助一个对比损失函数，通过最大化相同数据下不同增强方式的数据的一致性，以学习潜在空间中的表征。

<img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210915205223279.png" alt="image-20210915205223279" style="zoom:80%;" />

**思路是：通过F和G函数得到的Z通过对比损失函数的训练得到一个不错的representationH，自监督学习结束后，通过F函数和其他下游函数的监督训练得到想要的结果。**

主要的工作：

- 随机的数据增强模块：**随机转换任意给定的数据样本以得到该相同样本的两种不同相关视图view。同时这两个视图被称之为一对正例。**

    本文中**依次sequentially**使用了三种增强方式：

    - 随机裁剪，紧跟resize至原始大小；
    - 随机色彩变形color distortions；
    - 随机高斯滤波

    实验表明，随机裁剪和颜色扭曲对性能的增值幅度很大。

- 基础的神经网络编码器F：从增强的数据样本中提取表征向量。

    本文使用了残差网络，同时获得的H表征是经过了平均池化层的。

- 小型的神经网络projection head映射头G：将学到的表征H映射到对比损失函数所 **能**应用到的空间。

    利用了两个FC作为隐藏层以获取Z。

    **实验表明，利用Z进行损失函数计算要优于使用H。**

- 一个对比损失函数：为对比预测任务所定义。

    **对比预测任务旨在，在包含了数据增强的样本集S中，对于给定的增强样本x，辨识出S中x对应的另一个x。**

相关符号声明：

- batch_size中含有N个样本。经过一对数据增强，得到2N个数据样本。**作者没有对负例样本明确地采样。相反地，对于一对正例，作者将一个batch中剩下的2(N-1)个增强样本视为负例。**

- 用余弦相似度作为一对正例的表征的相似度。同时，损失函数定义为：

    softmax+log+T温度参数+01指示函数。

    ![image-20210915212507806](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210915212507806.png)

    为方便起见，我们将其命名为NT Xent（**归一化温度缩放**交叉熵损失）。

    > 深度学习中的temperature parameter是什么 https://zhuanlan.zhihu.com/p/132785733
    >
    > `t`越大，结果越平滑`*t*`*的大小和模型最终模型的正确率没有直接关系，*我们可以将`t`的作用类比于学习率。我们的label类似于[1,0,0]，最“尖锐”，如果我们在训练时将*`*t*`*设置比较大，那么预测的概率分布会比较平滑，**那么loss会很大，这样可以避免我们陷入局部最优解（因为局部最优解一般都是loss比较低的位置。）**。随着训练的进行，我们将`t`变小，也可以称作降温，类似于**模拟退火**算法，这也是为什么要把`t`称作温度参数的原因。**变小模型才能收敛**。比如我们可以这这样设置`t`:
    >
    > ![[公式]](https://www.zhihu.com/equation?tex=%5Ctau%3D%5Cfrac%7B%5Ctau_0%7D%7B1%2B%5Clog%7BT%7D%7D)
    >
    > 这里的`T`表示的是训练循环的次数。

#### 2 在较大batch_size训练

- 为了简单，没有使用内存块来训练模型，取而代之的是通过变动训练的batch_size，从256到8192。

- 在较大batch_size下，使用带线性学习率缩放的动量SGD用于训练，可能不太稳定，因此使用了LARS优化器。
- 基于云TPU。

**全局批归一化**

在数据并行的分布式训练过程中，BN平均值和方差通常在每个设备上进行**局部聚合**。而在对比学习中，由于正样本全部在相同的设备中计算，因此该模型可以利用**局部信息泄漏**来提高预测精度，而无需改进表示。

解决方法：训练期间，将所有设备上的BN的均值和方差进行聚合。

其他方法：不同设备之间的数据样本的打乱；用层范数代替BN。

#### 3 评估协议

**Dataset and Metrics.**

CIFAR-10 和 ImageNet ILSVRC-2012 dataset

为了评估学到的表示，作者沿用了**线性评估协议**：在冻结基网络上训练**线性分类器**，并将测试精度作为**表示质量**的代理。

除了线性评估，作者将对比学习和半监督学习以及前以学习进行了比较。

**Default setting.**

网络：残差网络-50；两层的MLP，将表示映射到128维；

优化器：LARS；学习率4.8（0.3 X Batch_size/256）；权重衰减10-6；

batchsize：4096 epoch：100；warmup：10；使用余弦衰减计划衰减学习速率，无需重新启动。

### 对比表示学习中的数据增强

数据增强定一个预测任务。目前有很多现存的方法通过改变结构来定义对比预测任务。

- 【2018|2019】通过限制网络结构中的感受野区域实现了全局向局部视图的预测；
- 【2018|2019】通过一个固定的图像分割程序和一个context融合网络实现了邻近视图预测。

<img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916135448306.png" alt="image-20210916135448306" style="zoom:80%;" />

而本文提出的随机裁剪的方式可以避免这种复杂性，同时还能囊括上面的两种方法。

- **这种简单的设计选择方便地将预测任务与其他组件（如神经网络体系结构）分离**。
- 更广泛的对比预测任务可以**通过扩展数据增强family和随机组合他们**来定义。

#### 1 数据增强操作的组合对学习好的表征至关重要

**数据增强类型介绍**

- 一类增强方式，涉及数据的空间/几何转换。比如裁剪、resize（含水平翻转）、旋转和cutout。

> cutout：**随机选择一个固定大小的正方形区域，然后采用全0填充就OK了，当然为了避免填充0值对训练的影响，应该要对数据进行中心归一化操作，norm到0。**

- 另一种增强方式，appearance transformation, such as color distortion外观变化，比如颜色失真（颜色丢失、亮度、对比度、饱和度和hue色调）、Gaussian blur高斯模糊和Sobel filtering索贝尔滤波。

<img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916140854674.png" alt="image-20210916140854674" style="zoom:80%;" />

**数据增强方式的effect和重要性分析**

由于ImageNet数据集的图片是不同size的，因此我们总是使用裁剪和resize图片，因此这样的现象使得我们很难在没有裁剪的情况下研究其他的增强方式。

为了摆脱这一点，我们**总是首先随机裁剪图像并将其调整到相同的分辨率**，然后将目标转换仅应用于**图2中框架的一个分支**，同时使另一枝保持本身。**请注意，这种不对称的数据扩充会影响性能**。尽管如此，这种设置不应实质性地改变单个数据扩充或其组成的影响。

我们观察到，**没有一个单一的转换足以学习良好的表征**，即使该模型几乎可以完美地识别对比任务中的正对。在组合增强方式时，**对比预测任务变得更加困难，但表示的质量显著提高**。

**增强的一个组成部分很突出：随机裁剪和随机颜色失真**。我们推测，当仅使用随机裁剪作为数据增强时，**一个严重的问题是，来自图像的大多数补丁共享相似的颜色分布。图6显示，仅颜色直方图就足以区分图像**。神经网络可以利用这一**捷径**来解决预测任务。因此，为了学习可概括的特征，用颜色失真合成裁剪是至关重要的

<img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916141358236.png" alt="image-20210916141358236" style="zoom: 67%;" /><img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916143654692.png" alt="image-20210916143654692" style="zoom: 67%;" />

#### 2 对比学习比监督学习更加需要效果更好的数据增强方式

针对颜色增强的强度进一步研究，如下。

发现：该对比框架从该颜色失真强度的变化中受到的影响程度大于监督学习。

**同时对监督学习的一个启发是：某些数据增强方式的种类以及强度对监督学习结果的影响是不一的，有时不升反降。**

<img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916143915692.png" alt="image-20210916143915692" style="zoom:67%;" />



### 编码器和Head组件的架构

#### 1 大体量模型对无监督对比学习比较有益

提升网络的深度和宽度有助于提升网络模型的性能。

<img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916145037131.png" alt="image-20210916145037131" style="zoom:67%;" />

**所谓的线性评估是指，最后的分类器是有MLP构成，而非其他复杂的网络结构。**

#### 2 非线性投影头提高了它之前层的表示质量

头部的三种结构对应的线性评估结果。

- identity；
- 线性映射；仅一个FC；
- 含有一个附加隐藏层的非线性映射；

![image-20210916145951854](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916145951854.png)

同时，图表反映出：

- 非线性的评估结果很不错；
- **非线性的评估结果几乎和输出维度无关**。
- <u>即使使用了非线性映射，有一件事一直没有被颠覆：映射头之前的隐藏层输出是一个比映射之后的结果，更好的表示</u>；



- 猜想：非线性映射头之前的表征之所以重要是因为对比损失函数引起的信息流失。特别的，非线性映射头使用后得到的表征对数据转换具有不变性，因此，映射头可能移除了对下游任务比较有用的信息，比如颜色或者物体的方向。**但是通过使用非线性转换G，更多的信息会被形成或者保留在了H表征中**。

- 为了验证上述假设，尝试用H或者Z以学习预测所应用的转换。表3表示，H包含了更多所应用的转换的信息，尽管Z流失了很多信息。（TODO：这一布不是很了解。）

### 损失函数和批量大小

#### 1 具有可调节的温度参数的归一化交叉熵损失函数要比其他选择要好

![image-20210916154643671](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916154643671.png)

观察到：（TODO：不知道如何从梯度公式中观察到的!）

- 正则化、温度参数能够有效地衡量不同样本的权重；而一个恰当的温度参数有助于模型学习负样本；
- 不同于交叉熵，其他的目标函数不能够通过其相对硬度**hardness**来衡量负例。因此，必须对这些损失函数应用**半硬负挖掘**（Schroff et al.，2015）：与其计算**所有损失项上的梯度**，还不如使用半硬负样本计算梯度（即，那些在损失间隔范围内且在距离层次最近的，但比正例更远的项）。

**衡量损失函数、使用半硬度的损失函数和NTXent损失函数的实验效果**

<img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916155739491.png" alt="image-20210916155739491" style="zoom:67%;" />

即使使用了半硬度挖掘，依旧无法匹敌NTXent。

**衡量正则项和温度参数的价值**

这里的正则项需要注意是，余弦相似度。而不使用正则项时使用的相似度计算函数是点积乘法；

<img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916160105276.png" alt="image-20210916160105276" style="zoom:67%;" />

**重要的是：**Without ` 2 normalization, the contrastive task accuracy is higher, but the resulting representation is worse under linear evaluation.



#### 2 大数目的批量大小和长时间的训练对对比学习比较有益

![image-20210916161622336](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916161622336.png)

这里的特征对比于**监督学习**不同的是：**对比学习中，较大的批量大小提供了更多的负样本，促使模型走向收敛**。对于一个确定的准确率，需要使用较少的epoch和step。—— TODO：存在疑问：批量大小 监督学习中不应该也是如此吗？

在迭代次数少的时候，大的batch可以提升更多，随着迭代次数加大，提升不会很明显。因此，**大Batch Size训练越容易提前收敛**；但是监督学习中，不然。

**但是训练时间越长，效果确实越好**；



### 与其他baseline的对比

仿照前人实验的方式，we use ResNet-50 in 3 different hidden layer widths (width multipliers of 1×, 2×, and 4×)

<img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916163253753.png" alt="image-20210916163253753" style="zoom:67%;" />



**线性评估**

重要的事情：在编码器上面放置分类器的时候，**在分类器的输入上使用了stop_gradient**，以防止标签信息影响编码器整体的参数。

但是精调的时候会放开编码器。

**半监督学习——Fine-tune**

以类别均衡维目的，从数据集中选择十分之一或者百分之一的数据量。大概每个类别的图片数目是128或者12.8张。

具体的细节：

- 动量0.9 + Nesterov优化器，batchsize 4096，lr 0.8 (LearningRate = 0.05 × BatchSize/256)  **无warmup**
- 预处理，训练时仅使用crop 同时 resize至 固定大小；推理时，先resize至256大小，再仅选择一张中间的crop；
- 不使用任何的regulation约束，比如weight_decay。
- 百分之一的标注数据，60epoch，百分之10的数据，30epoch。

<img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916162804097.png" alt="image-20210916162804097" style="zoom: 67%;" />

**迁移学习**

**注意：**在线性评估（固定特征提取器）上和精调设置**两个情况**下做了实验。

![image-20210916161914318](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916161914318.png)

### 相关工作

- 最近，有人在通过互信息以获取潜在表示；但是并不清楚：对比方法的成功是取决于互信息还是对比损失函数的具体的形式。

    > rumor的文章 就是用的互信息。

- 与以前的工作相比，**我们的框架的优势不是由任何单一的设计选择来解释的，而是由它们的组成来解释的**。

### 某些细节的代码实现

#### 数剧增强的两次视图的生成是否有差别

正常操作：裁剪-->颜色变形-->随机高斯滤波；

两次视图：因为这三个序列操作是随机性质的，因此只需要对同一样本进行了两次该操作，即可。

代码：

```python
def preprocess_for_train(image,height,width, color_distort=True,  crop=True, flip=True, impl='simclrv2'):
    if crop:
        image = random_crop_with_resize(image, height, width)
    if flip:
        image = tf.image.random_flip_left_right(image)
    if color_distort:
        image = random_color_jitter(image, strength=FLAGS.color_jitter_strength,
                                    impl=impl)
    image = tf.reshape(image, [height, width, 3])
    image = tf.clip_by_value(image, 0., 1.)
    return image


def preprocess_for_eval(image, height, width, crop=True):
    if crop:
        image = center_crop(image, height, width, crop_proportion=CROP_PROPORTION)
    image = tf.reshape(image, [height, width, 3])
    image = tf.clip_by_value(image, 0., 1.)
    return image


def preprocess_image(image, height, width, is_training=False,
                     color_distort=True, test_crop=True):
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)
    if is_training:
        return preprocess_for_train(image, height, width, color_distort)
    else:
        return preprocess_for_eval(image, height, width, test_crop)
    
# 上面的三个函数是三个数剧增强方式的执行过程。
def get_preprocess_fn(is_training, is_pretrain):
    """Get function that accepts an image and returns a preprocessed image."""
    # Disable test cropping for small images (e.g. CIFAR)
    if FLAGS.image_size <= 32:
        test_crop = False
    else:
        test_crop = True
    return functools.partial(
        data_util.preprocess_image,
        height=FLAGS.image_size,
        width=FLAGS.image_size,
        is_training=is_training,
        color_distort=is_pretrain,
        test_crop=test_crop)

preprocess_fn_pretrain = get_preprocess_fn(is_training, is_pretrain=True)
def map_fn(image, label):
    """Produces multiple transformations of the same batch."""
    if is_training and FLAGS.train_mode == 'pretrain':
        xs = []
        for _ in range(2):  # Two transformations
            xs.append(preprocess_fn_pretrain(image))
        image = tf.concat(xs, -1)
    else:
        image = preprocess_fn_finetune(image)
    label = tf.one_hot(label, num_classes)
    return image, label  # 因此这里的image其实是包含了两个image的。论文中提及的两个分布，其实也没有具体的不同。
dataset = dataset.map(map_fn, num_parallel_calls=tf.data.experimental.AUTOTUNE) # 批量处理。
```

#### 对比预训练的loss计算

<img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/E 对比学习/对比学习.assets/image-20210916121956503.png" alt="image-20210916121956503" style="zoom:80%;" />

```python
def add_contrastive_loss(hidden, hidden_norm=True, temperature=1.0,strategy=None):
    if hidden_norm:
        hidden = tf.math.l2_normalize(hidden, -1)
    hidden1, hidden2 = tf.split(hidden, 2, 0)
    batch_size = tf.shape(hidden1)[0]
    LARGE_NUM = 1e9
    
    hidden1_large = hidden1 # I
    hidden2_large = hidden2 # J
    labels = tf.one_hot(tf.range(batch_size), batch_size * 2)
    masks = tf.one_hot(tf.range(batch_size), batch_size)
    
    logits_aa = tf.matmul(hidden1, hidden1_large, transpose_b=True) / temperature # X-i  X-i
    logits_aa = logits_aa - masks * LARGE_NUM # 自身相似度减去mask，正值的部分表示与非正例；[batch_size ,batch_size]

    logits_bb = tf.matmul(hidden2, hidden2_large, transpose_b=True) / temperature  # X-i  X-i
    logits_bb = logits_bb - masks * LARGE_NUM

    logits_ab = tf.matmul(hidden1, hidden2_large, transpose_b=True) / temperature  得到的是
    logits_ba = tf.matmul(hidden2, hidden1_large, transpose_b=True) / temperature  # X-j  X-i

    loss_a = tf.nn.softmax_cross_entropy_with_logits(labels, tf.concat([logits_ab, logits_aa], 1))
    # logits的特点是 I与J的相似度和I内部除了与自身的样本的相似度
    loss_b = tf.nn.softmax_cross_entropy_with_logits(labels, tf.concat([logits_ba, logits_bb], 1))
    # logits的特点是 J与I的相似度和J内部除了与自身的样本的相似度
    loss = tf.reduce_mean(loss_a + loss_b)
    
    return loss, logits_ab, labels
```

- **softmax_cross_entropy_with_logits:** 就是先做softmax，再将输出log化后和实际标签做交叉熵。

> 【TensorFlow】tf.nn.softmax_cross_entropy_with_logits的用法 https://blog.csdn.net/mao_xiao_feng/article/details/53382790

- mask：实际上，通过配合softmax_cross_entropy_with_logits的sorftmax函数，使得自身样本之间的相似度值，以极小值的方式减轻对最终结果的影响。是使自身样本之间相似度变成0的近似表达。
    - 通过mask，使得矩阵中自身样本之间的相似度变成-1e9+1；
    - 经过softmax的指数化，变成极小值。



