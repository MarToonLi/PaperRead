### 《Transformation Driven Visual Reasoning》

定义了一种新的视觉推理范式，通过引进一个重要因素：transform

动机来源于一个事实：大多数现存的视觉推理任务被单独地定义以测试机器能够多么好的理解概念和像一个静态设置（比如一张图片）中关系。

我们认为这种由状态驱动视觉推理的方式已经在一个方面受到限制：反映是否机器拥有推断不同状态之间的动态的能力。而推断不同状态之间的动态是和 皮亚杰理论中人类认知的状态推理 一样重要。

鉴于初始和最终的状态，目标是推理对应的一步或者多步转换，呈现为一个三元组（物体、属性和值）或者一系列的三元组。

基于CLEVR数据集，构建了一个TRANCE数据集，包括三个层次的设置。比如：

- 基础：单步转换；
- 事件：多步转换；
- 视图：不同视角的多布转换；

#### 引言

视觉推理是在分析视觉信息的基础上**解决问题的过程**，远远超出了对象识别[11,21,32,33]。

对于视觉系统而言异常困难，因为它通常需要对世界的高阶认知和推理。

最近的一些视觉推理任务被提出：

- 视觉问题回答VQA：CLEVR定义了一个问题的回答范式，以测试机器是否对一张给定的图片具有空间、关系和其他推理的能力。
- 视觉蕴涵任务：NLVR，使模型决定关于两个图片的状态的句子是否是真的。
- 视觉常识推理任务：VCR，要求模型进一步提供解释为什么回答是正确的根本原因。

以往的任务都是专注于一张图片中的状态去做推理，但是鲜有人研究两张图片之间的动态关系，即转换。

研究动态关系，具体而言是分析图片中的每个物体的哪些属性发生了变换，属性值发生了怎样的变换。变换前后之间的转换函数是什么？

#### 模型

由此，提出了自己的研究方法：TranceNet。

![image-20210918111126143](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/D 视觉推理/视觉推理.assets/image-20210918111126143.png)

**编码器：**用以从图片对中提出有效的特征。提取方式有两种：

- 单流：直接输入两张图片得到特征

    直接融入的两张图片的预处理策略：

    - 相减。后一张减去前一张；
    - concatenation合并，

- 双流：单独提取每张图片的特征，在特征级别再融合。

**解码器：**输出一个比较feasible可行的转换序列。

由GRU网络和一个分类器构成。

- 分类器接受来自GRU单元中的初始物体的状态和当前的隐藏状态，之后输出物体的特征向量和当前步骤的值。

    具体地，物体的标识向量首先由隐藏层状态计算得到。然后，然后利用余弦相似度将**目标向量与初始目标们**进行匹配，得到目标编号。

    属性由值来反映，比如，蓝色表示属性为颜色，因此分类器的输出不显式包含属性。

**损失函数**

**![image-20210918110317487](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/D 视觉推理/视觉推理.assets/image-20210918110317487.png)**

o和v表示转换的第ℹ步的物体和值。n表示转换的步数。

