### 《A Second-Order Approach to Learning with Instance-Dependent Label Noise》

标签噪音的出现京汉藏舞蹈深度学习的训练；

争议点：**最近的文献大多假设标签噪声率仅由真实标签类决定，与此不同，人工标注标签中的错误更可能取决于任务的难度级别，从而导致设置与实例相关的标签噪声**。

贡献：

- 作者首先证明了**异构实例相关标签噪声以非均匀的方式有效地降低噪声率较高的示例的权重，从而导致不平衡，使得直接应用类相关标签噪声方法的策略受到质疑**。

- 基于最近的一项研究[24]，我们提出并研究了**二阶方法的潜力**，该方法利用**实例相关噪声率**和**贝叶斯最优标签**之间定义的几个**协方差项**的估计。
- 我们进一步证明，在估计的二阶统计量的帮助下，我们识别了一个新的损失函数，其在实例相关标签噪声下分类器的预期风险等价于仅具有类相关标签噪声的新问题。**这一事实**使我们能够应用现有的解决方案来处理这一经过更好研究的环境。我们提供了一种有效的方法来估计这些**二阶统计量**，而无需访问地面真值标签或噪声率的先验知识。在CIFAR10和CIFAR100上使用合成实例相关标签噪声和Clothing1M使用真实世界人类标签噪声的实验验证了我们的方法。



#### 引言

问题产生原因：深度神经网络在揭示和拟合特征X和标签Y之间的关系的方面，功力很强大。然而，标签Y通常需要人力准确的标注。**在有限的预算/努力下**，产生的数据集会有噪声，**标签噪声的存在**：

- 可能会误导DNN学习或**记忆错误的相关性**。
- 更糟糕的是，嵌入到人类注释中的标签噪声通常**依赖于实例**，**例如，一些困难的示例更容易被错误标记**（**这里解释了实例依赖的意思。**）
    - 这种被隐藏的和不平衡的噪音分布，也常常具有一个detrimental坏的影响。因此，**在实例依赖的标签噪音下进行学习是具有挑战性的。**

**以往的解决思路**：主要依赖于损失校正loss correction，需要估计噪声率。最近的研究考虑不依赖于估计噪声率而进行损失矫正的可能性。

- 建议的解决方案使用**适当指定的正则化器**来消除**实例相关标签噪声**的影响。

**以上思路的的共同theme是**：**专注于**通过使用模型预测的特定形式的**一阶统计量**来学习**潜在的干净的分布**。

**本文的思路**：在本文中，我们提出了一种二阶方法，**借助于附加的二阶统计量**，并探讨了这些信息**如何在依赖实例的标签噪声下**提高学习的鲁棒性。

**本文的贡献：**

- 最近的工作：主要依赖于一阶统计量（模型预测结果的期望值）以提升损失函数的鲁棒性。

    作者提出，二阶方法，同时**强调，在处理实例依赖的标签噪声的时候，**使用二阶统计量（几个协方差项）的重要性，

- 在**完全了解上述协方差项**的情况下，我们**确定了一个新的损失函数**，该函数将分类器在实例相关标签噪声下的**预期风险转换为仅具有类相关标签噪声的风险**，而，**类相关标签噪声的风险**，是一种更简单的情况，并且可以通过现有的解决方案很好地处理。

    基于peer loss，作者进一步展示了类相关噪音的期望风险，等价于一个贝叶斯优化分布下的期望风险的一个放射变换。

    由此，构建了一个新的损失函数：收敛协助学习CAL，它将产生相同的极小值，**就好像我们可以访问干净的Bayes最优标签一样**。

    > 类相关标签噪声是什么？风险是指什么？干净的贝叶斯最优标签是啥？

- 我们展示了如何使用现有的样本**选择技术**有效地估计二阶统计量。对于协方差项无法完全估计的更现实的情况，我们证明了我们的解决方案**在最坏情况下的性能保证**。

- **除了理论上的保证外**，在**具有合成实例相关标签噪声**的CIFAR10和CIFAR100数据集以及**具有真实人类标签噪声**的Clothing1M数据集上测试了所提出的二阶方法的性能。

    > 合成标签是指什么？真实标签，可能就是因为标注难度很简单，所以没有错误。

#### 1.1 相关文献

**有界损失函数：**

现象：一些研究将噪音标签视为异常，然而，the convex loss凸损失函数被证明倾向于产生错误，当异常样本存在的时候。

解决方式：

- 交叉熵损失函数CE，通过将温度参数引入对数函数和指数函数以实现泛化。

    注意，交叉熵损失函数在预测值接近0的时候，会grows explosively爆炸性增长。**为此，**依稀而解决方法专注于设计边界损失函数。

    - 这些方法专注于损失函数的数字性，同时，其中大多数没有**讨论正在处理的标签噪音的类型**。

**学习干净的分布：**

**为了容忍噪声**，有必要从统计学的角度理解标签噪声的影响。

基于**类相关假设**，损失可以在noise transition噪声过渡可获得时，被矫正。二噪声过渡可以通过挖掘锚点、利用聚集性、正则总变化或者最小化T的体积或者大小。

> 类条件噪音CCN：假设噪音标签与输入的特征无关。但是该假设已经被证明不符合实际；也就是对样本标记错误的概率不因为类别不同而发生变化。
>
> 一种简单的解释是：无论从直觉还是理论上看，每个图片被误标记为不同标签的概率都应该是不一样的。
>
> ![image-20210925194635984](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/I 标签平滑/标签平滑.assets/image-20210925194635984.png)
>
> 实例依赖噪音假设：假设在类别给定的时候，噪音标签和输入的特征是相关的。
>
> ![image-20210925194927046](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/I 标签平滑/标签平滑.assets/image-20210925194927046.png)
>
> IDN假设的问题：
>
> - 比CCN更容易拟合和过拟合，因为与特征相关的噪音可以迷惑IDN，
> - 记忆效应的重要性被削弱，

损失矫正方法严重依赖于所估计的噪音过渡矩阵的质量。为了试该矩阵更具有鲁棒性，松弛变量或者一个乘法对偶可以用于revision。

**从统计学的角度，损失矫正方法正在学习当过渡矩阵十分完美时，学习到潜在的干净的分布。**

当类相关噪音率已知，surrogate loss替代损失（一个面向二分类非偏置的损失函数）同样可以学习到潜在的干净分布。

另外，对称的交叉熵损失函数，一种基于信息的损失函数，基于peer loss的相关一致，

**其他的研究方法：**

其他方法存在更复杂的训练框架或管道，包括**样本选择**[5,12,16,18,37,46,44]、**标签校正**[13,21,33]和半监督学习[19,28]等。

#### 2 预备知识

基于N个基于实例依赖标签噪音的训练样本，分类问题。

对重要的定义做出总结：

**干净分布：也就是真实的数据-标签分布**；含有真实标签的样本被称为干净样本。

**贝叶斯最优分布**：基于特征X得到的最优标签。

注意，最优分布不同于干净分布。

基于一个事实：特征和标签之间的编码的信息，被标签噪音干扰，因此干净标签和贝叶斯最优标签都是不可观测到的，因此，从噪音数据集中推断出贝叶斯最优分布时一项复杂的任务。

注意，这里现存两种方法为构建贝叶斯最优数据集提供保障。

同时，我们需要提醒各位读者，噪音标签、干净标签和贝叶斯最优标签可能彼此冲突。

**目前大多数的研究都专注于解决贝叶斯最优分布**，通过推断该贝叶斯分布，我们可以，估二阶统计量。

**噪音过渡矩阵T**：

传统的说，噪音过渡矩阵是基于**干净分布和噪音分布之间的关系**而被定义的。

最近的研究表明：

- 贝叶斯最优标签同样扮演了一个重要角色。

    在图片分类这样一个性能通过干净测试准确率来衡量的任务而言，对贝叶斯最优标签的预测达到了最好的性能。**而这一事实，**促使我们基于贝叶斯最优标签以定义一个新的噪音过渡矩阵。

    ![image-20210925202404775](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/I 标签平滑/标签平滑.assets/image-20210925202404775.png)

**其他的注解**

**目标：**不同于其他损失函数，专注于恢复干净分布的性能，我们旨在从噪音分布中学到一个分类器F，因此，在搜索贝叶斯最优分类器的意义上，我们的目标与关注清洁分布的目标是一致的

#### 一阶统计的不足

- 对等损失[24]及其启发的置信正则化器[5]是最近引入的两种稳健损失，在不了解噪声转移矩阵的情况下运行，这将**它们作为更复杂噪声设置的首选解决方案**。
- 在本节中，我们将首先回顾一阶统计量在对等丢失和置信正则化器中的用法（第3.1节），然后分析在处理挑战性IDN时仅使用一阶统计量的不足（第3.2节）。此外，我们将剖析IDN的降权效应，并提供**如何使IDN更易于处理**的直观信息（第3.3节）。
- 我们使用对等损失**将我们的论点形式化**，主要是因为1）其清晰的**分析形式**，2）我们后来提出的解决方案也将**建立在对等损失的基础上**。尽管我们关注**同伴流失**，但我们相信，**当其他现有培训方法满足IDN要求**时，这些观察结果通常是正确的。

#### 3.1 peer loss 中使用一阶统计量

##### 3.2. Peer Loss with IDN



#### 3.3. Down-weighting Effect of IDN

我们通过研究IDN对训练的不同影响，进一步讨论动机和直觉。**直观地说，高噪声率会降低特定示例（x，y）的信息量，因此会“降低”其对训练的贡献**。我们现在通过分析在同伴丢失情况下显示了这一点。



**我们能从这个观察中学到什么？**

- 首先，我们展示了对等丢失已经降低了更嘈杂示例的重要性。然而，简单地丢弃具有潜在高水平噪声的示例可能会导致分类器学习有偏分布。
- 此外，**主观上容易混淆的例子更容易被错误标记，对准确预测至关重要**[34]，因此需要仔细处理。
- 我们的第二个观察结果是，**如果我们找到一种方法来补偿上面所示的降权效应所造成的“不平衡”，则具有挑战性的依赖实例的标签噪声可以转化为依赖类的噪声**，而现有技术可以处理这种噪声。更具体地说，上述结果表明，**降权效应以T（X）为特征**，**这意味着仅使用模型预测的一阶统计量而不考虑噪声转移矩阵的分布T（X）不足以捕获学习任务模型的复杂性**。
- 然而，**准确估计T（X）是禁止的，因为要估计的参数数量几乎为O（N K 2）-回忆N是训练示例的数量，K是类的数量**。尽管我们可以粗略估计T（X），但依赖于估计的T（X）应用元素校正可能会累积误差。
- 因此，**为了实现从依赖实例到更容易依赖类的转换，我们需要借助T（X）的其他统计特性**。



#### 4. Covariance-Assisted Learning (CAL)

根据第3.3节中的分析，我们知道**依赖于实例的标签噪声**将“自动”为具有不同噪声率的示例分配不同的权重，从而导致不平衡。

在这种降权效应下，当最优解不变时，基于对等丢失的一阶统计量[5,24]工作良好。然而，**对于一个更稳健和通用的解决方案，使用额外的信息来“平衡”不同示例的有效权重是必要的**。

**虽然Bayes最优分布在实际实验中是不可访问的**，但我们首先假设它在理想情况下的理论分析中存在，然后我们将讨论当我们只能使用可以有效构造的代理D̂时与此最优解的差距。



#### 4.1. Extracting Covariance from IDN





##### 4.2. Using Second-Order Statistics

**使用协方差项的优点：**

- 使用建议的协方差项有几个优点。与根据D直接更正标签不同∗ , **所提出的协方差项可以看作是一种“软”校正**，它保持了在原始噪声标签和估计的贝叶斯最优标签中编码的信息。如[13]所述，保留这两种信息是有益的。此外，与直接损失校正方法[30,40,41]相比，我们保留了最初的学习目标，并使用额外的术语进行“校正”。

- 与这些直接端到端损耗校正方法相比，我们的方法在实践中更加稳健，原因有两个：
    - 1）**协方差项使用平均项**总结了复杂噪声的影响，表明我们的方法对单个示例的估计精度**不太敏感**；
    - 2） 如第4.3节所示，所提出的方法可以**容忍访问不完美的数据**∗ . 估计协方差项依赖于从分布D中提取的样本∗ . 
    - 因此，我们需要构造一个数据集D̂，它是相似的或无偏的w.r.t.D∗ . 我们将首先展示构造D̂的算法，然后提供DNN实现的细节。



###### 4.2.1 Constructing D̂

- 为了实现**方差项的无偏估计**，构造D̂的高级直觉是**通过将（噪声）标签分类的可能性、置信度或损失与某些阈值进行比较来确定e是否是Bayes最优的**，无论每个示例的标签是否在D中。

- 构造D̂有几种方法：蒸馏法[6]、搜索开发法[44]和样品筛法[5]。如果模型没有过度拟合标签噪声并学习噪声分布，则[6]和[44]中的两种方法都能很好地工作。
- 然而，对于具有**挑战性的依赖于实例的标签噪声**，过拟合很容易发生，因此有必要使用避免过拟合的技术。**在本文中，我们主要采用[5]中提出的样本筛来构造D̂，该样本筛使用置信正则化器来避免过度拟合**。
    - 具体而言，如[5]所示，在每个历元t中，每个示例的正则化损失由参数αn，t进行调整，**该参数可基于线性时间内的模型预测进行计算**。在[5]中假设的理想情况下，任何具有**正调整损失的示例**都会损坏（标签错误）。





###### 4.2.2 Implementations

对于使用**深度神经网络解决方案**的实现，我们需要**根据D̂估计转移矩阵**T（X），并随着随机梯度下降（SGD）更新**估计协方差项**

![image-20210926135030402](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/I 标签平滑/标签平滑.assets/image-20210926135030402.png)

##### 4.3. CAL with Imperfect Covariance Estimates

**定理4**显示了D̂τ的质量控制着**最坏情况误差上界的规模**。与定理1中不使用协方差项相比，我们知道当τ∈ [0.5, 1]. 

也就是说，当构造D̂τ优于包含D中每个实例的数据集时，借助**协方差项的训练**将在贝叶斯最优分布上获得更好的（最坏情况）精度∗ 随机选择，有50%的几率。

![image-20210926134709669](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/I 标签平滑/标签平滑.assets/image-20210926134709669.png)



#### 5 实验

##### 5.1. General Experiment Settings

**Datasets and models：**

- we use ResNet34 for CIFAR10 and CIFAR100 and ResNet50 for Clothing1M.

- peer term 选择的是【5】中的置信正则化CR，**它很稳定，同时收敛更快**
- 悬链使用cores；
- 为了数字稳定，使用交叉熵损失函数的cut-off版本。同时设置epsilon设置为1e-5。同时也是协方差项的spsilon值。
- All the experiments use a momentum of 0.9. The weight decay is set as 0.0005 for CIFAR experiments and 0.001 for Clothing1M.

**Noise type：**

- 对于CIFAR数据集，**依赖实例的标签噪声**是按照[5,40]中的方法生成的。基本思想是为**每个类随机生成一个向量**（总共K个向量），并将每个传入特征投影到这些K个向量上。通过联合考虑干净标签和投影结果，添加标签噪声。详见附录D.2。通常，**噪声率η是整个数据集中标签错误的示例的总比率**。
- 对于Clothing1M数据集，我们训练了**100万**个噪声训练示例，对真实世界的人类噪声进行编码。

![image-20210926133858093](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/I 标签平滑/标签平滑.assets/image-20210926133858093.png)

##### 5.2. Baselines

- 我们将我们的方法与一些相关的工作进行比较，其中**交叉熵损失**作为一个共同的基线进行测试。

- 此外，将**广义交叉熵[**50]作为**平均绝对误差和为标签噪声设计的交叉熵**的推广进行比较。
- 还选择了流行的**基于损失校正**的方法[29,40,41]、基于**样本选择的方法**[5,12,37,46]和**噪声鲁棒损失函数**[24,43]进行比较。
- **所有比较的方法都采用类似的数据扩充**，包括标准随机裁剪、随机翻转和标准化。注意：最近关于**零件相关标签噪声[**40]的工作没有在CIFAR数据集上应用随机裁剪和翻转。
- 为了与[40]进行公平比较**，我们从我们的方法中删除了相应的数据扩充**，并将比较推迟到附录D.3。**不包括具有额外特征提取和数据增强的基于半监督学习的方法**。使用独立合成的IDN重复所有CIFAR实验5次。清洁测试数据集的最高精度**在5次试验中平均**，以显示每种方法的最佳泛化能力。



##### 5.3. Performance Comparisons

###### 5.3.1 CIFAR

- 在CIFAR数据集上的实验中，我们使用了128个批大小，初始学习率为0.1，并在60时将其减少了10倍。

- 构造D̂为了构造D̂，我们通过最小化ℓ cores2（无动态样品筛）并应用算法1，最小值=L最大值=−8，对于数值稳定的解......
- 与CAL一起训练，估计D∗ , 我们重新训练100个时代的模型。对于CIFAR10，超参数β设置为1，对于CIFAR100，超参数β设置为10。注：如果可用干净的验证集，则可以更好地设置超参数（L min、L max、β）。
- 性能 表1比较了使用不同级别的合成实例相关标签噪声训练模型时，干净测试数据集上测试精度的平均值和标准偏差。所有比较的方法都使用ResNet34作为主干。在CIFAR10上，当标签噪声较低（η=0.2）时，所有比较的方法都表现良好，平均测试精度高于标准CE损耗。
- 在CIFAR100上也有类似的观察结果。**通过将CAL与Core2进行比较**，我们得出结论，所采用的二阶统计量工作得很好，并带来了不平凡的性能改进。此外，在η分别为0.4和0.6的CIFAR100数据集上，**我们观察到Reweight-R[41]具有较大的标准偏差和相对较高的平均值**，**<u>表明它在某些试验中的表现可能与CAL一样好，甚至比CAL更好。</u>**它还显示了在严重且具有挑战性的依赖实例的标签噪声设置中使用修正的转移矩阵T[41]的潜力。

###### 5.3.2 Clothing1M

- 对于Clothing1M，我们首先按照[5]中的设置训练模型，并使用最佳模型构建D。注意到Clothing1M中噪声标签的总体准确率约为61.54%[42]，我们设置了适当的L min=L max，以使61.54%的训练示例满意ℓ 核心2− αn，t≤ L分钟。使用D̂，我们通过**随机选择每个类的18976个噪声示例**来采样一个类平衡数据集，**并继续使用β=1和初始学习率为10**来训练模型−120个时代中有5个。其他参数设置如下[5]。更多详细的实验设置见附录D.4。表2显示CAL在真实的人类噪声中表现良好。

- 具体地，构造D̂我们首先使用[5]中的方法，在100万张有噪声的训练图像上训练120个时代的网络。批大小设置为32。**初始学习率设置为0.01，并在30、60、90个阶段减少10倍**。我们从每个历元的训练数据中抽取1000个小批量样本，**同时确保（噪声）标签是平衡的**。数据扩充采用**混频[**48]。超参数β在前80个时期设置为0，接下来20个时期线性增加至0.4，其余时期保持为0.4。我们用最好的模型构造D̂。
- **使用CAL训练我们在获得D̂后将损失更改为CAL损失**，并以10的初始学习率继续训练模型（无混淆）−120个时代为5（在30、60、90个时代减少10倍）。我们还使用D̂对模型进行了重新训练，获得了73.56的精度。一个随机收集的平衡数据集，每个班级有18976个噪声样本，用于CAL训练。为便于实施，不在该平衡数据集中的示例将从D̂中删除。

![image-20210926131041862](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/I 标签平滑/标签平滑.assets/image-20210926131041862.png)



##### 5.4 消融实验

- 表3显示了**协方差项或对等项either the covariance term or the peer term**都可以单独工作，**并且在它们共同工作时可以显著提高性能**。

- 比较第一行和第二行，我们发现即使没有对等项（CR），二阶统计量也可以很好地工作（η=0.4除外）。
- 在第4行中，我们展示了第65epoch的性能，因为二阶统计量是根据该epoch的模型预测进行估计的。通过比较第4行和第5行，**我们知道二阶统计量确实会导致性能的显著提高**.即使当η=0.4时，协方差项单独只能达到78.49的精度，但当使用对等项时，它仍然可以贡献超过1%的性能改进（从84.41%到85.55%）。这一观察结果表明了CAL的鲁棒性。

![image-20210926125741011](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/I 标签平滑/标签平滑.assets/image-20210926125741011.png)



#### 6 致谢

本文提出了一种二阶方法，将具有挑战性的**实例相关标签噪声**转化为**类相关标签噪声**，从而可以**实现现有的针对类相关标签噪声**的方法。目前，**基于样本选择方法估计协方差项**的必要信息。这项工作的未来方向包括**扩展到准确估计协方差项**的其他方法。我们还对探索二阶信息与其他稳健学习技术的结合感兴趣。





### 《Peer Loss Functions: Learning from Noisy Labels without Knowing Noise Rates》

基于噪音标签学习是监督学习的普遍挑战，现有的一些方法经常需要practitioners从业者，指出噪音率，**控制问题中标签噪声严重程度**的一组参数，假设给定或使用附加步骤**估计规范**。

本文，引出一个全新的损失函数，能够从噪音标签中学习，同时不需要**噪声率的先验规范**。

**同行损失函数**在**标准经验风险最小化**（ERM）框架内工作。我们证明，在温和的条件下，对噪声数据执行带有对等损失函数的ERM会导致最优或接近最优的分类器，**就像对我们无法访问的干净训练数据执行ERM一样**。

**对等损失**提供了一种**简化模型开发**的方法，在使用可能有噪声的训练标签时，可以将其**推广**为这种情况下的鲁棒候选损失函数。

#### 引言

之前的文献研究如何在没有验证的情况下从自利代理人那里获取信息。**同行预测文献中的结果侧重于设计评分函数**，**使用另一个有噪声的参考答案**对每个报告数据进行评分，而**无需访问基本真相信息**。我们借用了这一思想和相关的评分函数，通过**将每个分类器的预测**作为代理的私有信息来获取和评估，并将嘈杂的标签作为“嘈杂标签代理”报告的不完美参考答案来建立联系。特定形式的对等损失使用待评估样本和精心构建的“对等”样本上的噪声标签来评估分类器的预测。





### 参考文献

- Learning-with-Label-Noise https://github.com/subeeshvasu/Awesome-Learning-with-Label-Noise
- [腾讯优图：带噪学*和协作学*，不完美场景下的神经网络优化策略](https://www.cnblogs.com/ccloud/p/12894817.html) https://www.cnblogs.com/ccloud/p/12894817.html

