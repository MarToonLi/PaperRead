### 《RESEARCH ON REGIONAL CLUSTERING AND TWO-STAGE SVM METHOD FOR CONTAINER TRUCK RECOGNITION》

#### 摘要

随着港口的大规模化、集成化和智能化，许多港口开始使用智能检测系统以使得操作变得更加高效。

**集装箱卡车识别和定位系统**也开始应用于集装箱码头区，以协助码头起重机和集装箱卡车之间的联合作业。然而，传统的基于运动区域检测的车辆检测无法识别运动目标的类型，传统的模式识别方法不能满足**实时性**的要求。

为了解决这些问题，本文提出了**一种区域聚类与两阶段SVM分类器**相融合的算法。该方法包括两个阶段，分别在码头起重机上的两个摄像系统中执行。

- 在第一阶段中，使用快速运动区域聚类算法检测运动图像块作为卡车候选子窗口。
- 在第二阶段，通过优化的两阶段SVM分类器在这些子窗口中识别集装箱卡车。

在集装箱码头的实验结果表明，与现有的传统算法相比，基于区域聚类和两阶段支持向量机的融合算法具有更高的效率和更好的卡车识别性能。

#### 引言

通常，集装箱卡车应该将自己停在合适的位置，等待quay cranes马都起重机上拉或者下方集装箱。

根据集装箱的操作设计，码头起重机自身停止，面向将装载的船舶的海岸。再整个上拉的期间，起重机从不移动自己。因此集装箱卡车应该将自己停放在起重机下方的合适的位置，以便码头起重机上拉或者下放集装箱。

在过去，驾驶员将集装箱卡车停放在正确的位置，是通过码头边上的工人的引导。但是这些引导操作耗时，同时对操作性能也有一些不好的影响。因此，岸边集装箱卡车 的检测和定位，已经称为了港口物流领域比较热门的工程维提之一。

在最近，研究员和工程员，尝试寻找和研发一种适合的实时的方法以快速地准确地检测和定位卡车。

车辆的识别和定位一直都是热门研究领域：

- 使用磁传感器以检测和跟踪路上的车辆。方法稳定同时检出率recall factor比较好，但是仅仅使用磁传感器无法区分车辆的类型。**而岸边，不仅仅只有集装箱卡车，还有其他的车辆，比如bus和皮卡车。**
- 雷达同样应用于港口工程。
    - 【11】将雷达应用于传播识别。
    - 【10】基于卷积网络和3DLidar激光雷达进行检测；
    - 【3，21】将激光雷达、毫米波雷达、GPS和视觉系统融合起来，以检测和定位车辆，另外，他们同样可以识别一部分的车辆类型，**然而，这些方法复杂且成本高**，港口终端用户无法接受高度不经济和复杂的解决方案。

视觉系统的崛起：

- 【12，13】设计了一个人类检测系统和一个集装箱拐角casting识别系统；

- 【14】开发了一种立体检测方法，用于将**待检测的大型元素**聚集在一起，并**移除用于港口卡车**检测的小型对象

    但是该方法无法识别车辆的正确类型。

- 【5】融合了几种算法用于检测、定位和估计车辆的位移displacements和速度。

    混合算法肯呢各准确率高，但是会比较满，因为许多算法集成到这一种系统之中。

- 【4，7，15，19，25，26】提出通过背景检测和运动区域追踪以实现车辆检测、识别和定位。

    这些方法计算快速，能够跟踪任何运动区域。然而，车辆识别肯呢各并不准确，因为车辆信息比较受限。

    为了能够准确分辨车辆类型，模式识别方法被提出。

- 【1，2，18，27】提出一种a monocular and binocular单筒或者双筒望远镜的视觉方法，基于深度卷积网络，以搜寻整张图中的车辆。

- 【6,8,10,23,24】使用多层分类器，深度学习分类器或者神经网络以识别车辆。

    这些方法使用**滑动窗口和多尺度窗口**扫描整个图像并找到车辆目标。

    这种扫描整张图像的方法使得高准确率，但是慢于其他的方法。因此，实时计算的性能难以满足。

总结：

作为**港口卡车识别的未来**，车辆识别中的**视觉系统**主要包括两种算法：运动区域检测和模式识别。

然而，使用运动区域检测的传统车辆检测方法无法识别运动物体的具体类型，同时传统的模型识别方法无法满足实时的要求。

因此，作者提出了一种快速的卡车识别方法：综合了区域聚类和两阶段分类器。

具体介绍：

- 两个 **独立于两个相机系统的** 阶段：
    - 预搜索阶段：码头起重机上面的相机会手机整个车道的图片，然后快速的运动区聚类算法被用于检测移动的物体，作为卡车候选子窗口。之后，整个图片会被分割成不同的子窗口，作为卡车检测候选窗口。
    - 第二阶段：如果确实存在任何的候选窗口，另一个相机开始识别集装箱卡车，使用优化后的两阶段SVM分类算法。最终，多尺度识别结果被融合以获得准确的集装箱卡车中心位置。

作者提出的方法能够实现：检测、定位和识别的功能。

#### 2 卡车位置的快速检测

##### 2.1 相机安装和算法框架

两类相机：预搜索相机和卡车检测相机

- 两个相机的检测区域有重叠，相机可以检测卡车进出的全过程；
- 预搜索相机整天保持工作，而卡车检测相机standby 睡眠模式，等待预搜索相机发送激活信息。

两个相机协同处理过程：

- 预搜索相机快速搜集候选子窗口，同时检测视频序列中是否存在移动物体。如果有检测到，则将含有移动物体的候选窗口的信息发送给相机。

    - 首先，背景图片根据图片序列，通过高斯混合模型，生成；

    - 然后，运动物体的图片patch江北提取出来，通过背景subtraction减法方法；

    - 接着，图片patch通过K-means聚类，接着获取聚类的外部矩形帧。

        通过多这些矩形帧的过滤，候选子窗口，基于一些参数条件被选择。

    - 激活卡车检测相机。操作全部作用于对应的候选窗口。

- 接着，卡车检测相机将会在对应图片的子窗口中准确检测到卡车的位置。

    - 首先，从候选窗口中，提取HOG特征，以训练两阶段SVM分类器；
    - 然后，使用分类器，面向候选滑动窗口，检测两种shape的卡车。
    - 最终，分类器的预测结果被融合，最终的融合结果就是最终的卡车位置的坐标。

##### 2.2 快速的预搜索算法

卡车头的形状在相同的terminal终端中并不统一，而卡车拖车的形状也因为是否装载集装箱而有巨大的差异。**因此卡车的检测实际上意味着对卡车头部的检测**。

**快速寻找的关键：**从原始图片中寻找到卡车可能的位置区域。

- 避免了对整个图片的扫描。
- **预搜索算法可以根据每个搜索结果选择自适应分类器，避免了两级分类器同时检测的资源浪费**。

因此，背景裁剪法被视为本文的卡车预搜索方法被应用。具体的：

- 背景提取和更新

    - 首先，原始的RGB图像被转换为灰度图；

    - 接着，高斯混合模型实现对背景的提取。

        <img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/G 港口/港口md.assets/image-20210924160643553.png" alt="image-20210924160643553" style="zoom:50%;" />

        - 为了适应多峰的背景场景，高斯混合模型通过施加权重以被建立，因此它可以处理复杂的背景场景。

            ![image-20210924160854681](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/G 港口/港口md.assets/image-20210924160854681.png)

- 背景削减

    通过背景帧和当前帧的subtraction，如果像素值很小，意味着没有移动的物体，否则，在对应的区域，应该存在着一个卡车。

    <img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/G 港口/港口md.assets/image-20210924161204490.png" alt="image-20210924161204490" style="zoom:50%;" />

- 区域聚类

    对于大规模的图片数据，传统的聚类算法不能胜任，因为图片的每个像素点的遍历操作。**而区域聚类不同：**

    - 首先，相同连接区域的白色点，被视为一个元素。而每个元素包含一系列的属性参数，比如中心节点坐标，连接区域范围和the radius of outer circle。

    - 然后，图片数据的大量点可以被映射到低维空间，接着被聚类。

        通过借助欧几里德空间加权距离方法，区域聚类可以通过一个评估函数（类中点坐标到聚类中心的距离）以评估。

        **通过聚类，得到两个类别：含有卡车的patch，不含卡车的patch**

        <img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/G 港口/港口md.assets/image-20210924162138565.png" alt="image-20210924162138565" style="zoom: 67%;" />

        ​	对于patch，得到坐标数据：ABCD一个框的四个边界的中心坐标。

        <img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/G 港口/港口md.assets/image-20210924162329372.png" alt="image-20210924162329372" style="zoom:50%;" />

        <img src="/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/G 港口/港口md.assets/image-20210924162339308.png" alt="image-20210924162339308" style="zoom:67%;" />

- **候选框选择**

    上一个步骤中的含有卡车和不含有卡车的patch被称为矩形帧，同时被保留视为候选子窗口，一起被保留的还有一些指标：area的大小，宽高和角度。

    **但是这里的问题是，提取到的这些指标，只能呢各提供大概的范围，不并具备充足的准确率。**

##### 2.3 卡车位置的检测算法

大致将使用：滑动窗口算法；问题：两个相机安装位置对应且监控区域重叠。

因此正式进入该布之前，图片的坐标应该被转换，以期与另一个相机的视角相一致。

- 局部特征提取；

    HOG特征

- 分类器模型的训练

    SVM分类器和卡车的位置

- 结果的融合；

    每个滑动窗口经过该分类模型得到的卡车位置的结果将会融合以得到最终的卡车位置的预测。

###### 2.3.1 局部特征提取

特征提取分为五个步骤：

- gamma相关操作；
- 梯度计算；
- HOG描述子计算；
- 特征归一化；
- 特征向量结合；

但是即是提取到HOG特征，在真实的图片中，物体的形状特征也会因为卡车处于图片的上半部分或者下半部分，而存在差异。因此，两个样本数据的几何被需要训练卡车的不同形状。如10图所示。

![image-20210924165027625](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/G 港口/港口md.assets/image-20210924165027625.png)

###### 2.3.2 分类器模型：训练和预测

使用SVM分类器处理卡车位置，每个样本图片的大小是80 X 64，同时多为特征空间，

所使用的SVM的特殊：相比于传统的单一SVM分类器，卡车的不同位置，需要两阶段的SVM分类器对卡车进行检测。

![image-20210924165421978](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/G 港口/港口md.assets/image-20210924165421978.png)

涉及到具体的SVM变动理论介绍，省略。

在预处理阶段，两阶段SVM分类器算法首先，将卡车样本分成唢呐类：处于图片下半部分的卡车、上半部分的卡车和不存在卡车。

![image-20210924165841016](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/G 港口/港口md.assets/image-20210924165841016.png)

- 首先，**每个从卡车图片中选择出的样本**需要被作出一个二分决策：图片的上半部分还是下半部分。

![image-20210924165859813](/home/cold/PaperReadFastly/PaperRead/论文阅读列表/2021年度/G 港口/港口md.assets/image-20210924165859813.png)

> 如何确定，得到的含有卡车的patch，卡车头能完全处于patch中。？？？todo：

- 其次，该分类器将所有样本在两种情形下，分成两类：含有truck的patch和不含卡车的patch。
- 最终，可能的卡车区域会被分类器用于检测卡车的位置。

训练分类器的步骤：

- 预训练：

    根据卡车车道上拍摄的图像，卡车的窗口大小为80x64像素，作为正样本。当然，上半区域卡车和下半区域卡车将是两阶段分类器的阳性样本。

    除了卡车以外，图片的其他部分会被cut 作为负样本，然后，HOG特征将会被从正样本中提取且标注。

- 初始化SVM分类器训练

    - HOG特征提取后，会得到一个2268维度的特征性向，
    - 该向量会被映射到一个更高维度的空间，通过径向基函数RBF；如此之后，样本的HOG特征将被线性分割。
    - 通过主函数和约束函数进行优化。

- 最终的SVM分类器的训练

    训练的时候，有时候一些负例样本在初始分类器中很难得到正确的分类结果，因此，这些样本一称为硬样本，同时这些硬样本的HOG特征会被提取出来，同时和初始的HOG特征结合以作为一个新的负例样本。

###### 2.3.3 融合结果

所有的候选窗口需要通过一个多尺度滑动窗口的方式被扫描；而在扫描的过程中，相同的卡车会以不同的尺度和位置被多次检测到。融合结果就意味着**将滑动窗口下的大小和精度位置恢复到原始图像中**，并对这些位置进行聚类。根据位置结果，平均偏移方法用于融合所有卡车位置的坐标。

#### 3 结果和讨论

1000张图片，随机采样得到20份，每一份的测试样本数目是50个。

